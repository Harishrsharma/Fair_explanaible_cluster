{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93f0e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "\n",
    "from scipy.spatial.distance import cdist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01d63f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_CLUSTERS = 3\n",
    "P = 1\n",
    "Q = 1\n",
    "RANDOM_STATE = 42\n",
    "SAMPLE_SIZE = 1000\n",
    "MAX_TREE_DEPTH = 5\n",
    "MIN_NODE_SIZE = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc5d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        r'D:\\Thesis\\Fair_explainable_cluster_updated_2nd_feb\\data\\bank-full.csv'\n",
    "    )\n",
    "\n",
    "    df['sensitive'] = df['marital'].apply(\n",
    "        lambda x: 1 if x == 'married' else 0\n",
    "    )\n",
    "\n",
    "    drop_cols = ['marital', 'sensitive', 'y']\n",
    "    X_raw = df.drop(columns=drop_cols)\n",
    "\n",
    "    sensitive = df['sensitive'].values\n",
    "\n",
    "    if SAMPLE_SIZE < len(X_raw):\n",
    "        idx = np.random.choice(len(X_raw), SAMPLE_SIZE, replace=False)\n",
    "        X_raw = X_raw.iloc[idx].reset_index(drop=True)\n",
    "        sensitive = sensitive[idx]\n",
    "\n",
    "    categorical_cols = X_raw.select_dtypes(include=['object']).columns\n",
    "    numeric_cols = X_raw.select_dtypes(include=['number']).columns\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "    X_processed = preprocessor.fit_transform(X_raw)\n",
    "\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "    return X_processed, sensitive, feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bede38fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "\n",
    "    def __init__(self, indices, depth=0):\n",
    "        self.indices = indices\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.depth = depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de932e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(X, indices, depth=0):\n",
    "\n",
    "    if depth >= MAX_TREE_DEPTH or len(indices) <= MIN_NODE_SIZE:\n",
    "        return TreeNode(indices, depth)\n",
    "\n",
    "    dim = depth % X.shape[1]\n",
    "    values = X[indices, dim]\n",
    "    median = np.median(values)\n",
    "\n",
    "    left_indices = [i for i in indices if X[i, dim] <= median]\n",
    "    right_indices = [i for i in indices if X[i, dim] > median]\n",
    "\n",
    "    if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "        return TreeNode(indices, depth)\n",
    "\n",
    "    node = TreeNode(indices, depth)\n",
    "    node.left = build_tree(X, left_indices, depth+1)\n",
    "    node.right = build_tree(X, right_indices, depth+1)\n",
    "\n",
    "    return node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44d28977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fairlets_from_node(indices, sensitive):\n",
    "\n",
    "    reds = [i for i in indices if sensitive[i] == 1]\n",
    "    blues = [i for i in indices if sensitive[i] == 0]\n",
    "\n",
    "    fairlets = []\n",
    "\n",
    "    while len(reds) >= Q and len(blues) >= P:\n",
    "        r = [reds.pop() for _ in range(Q)]\n",
    "        b = [blues.pop() for _ in range(P)]\n",
    "        fairlets.append(r + b)\n",
    "\n",
    "    leftovers = reds + blues\n",
    "\n",
    "    return fairlets, leftovers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e9b7f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_fairlet_decomposition(node, X, sensitive):\n",
    "\n",
    "    if node.left is None and node.right is None:\n",
    "        fairlets, leftovers = extract_fairlets_from_node(\n",
    "            node.indices, sensitive\n",
    "        )\n",
    "        return fairlets, leftovers\n",
    "\n",
    "    left_fairlets, left_leftovers = tree_fairlet_decomposition(\n",
    "        node.left, X, sensitive\n",
    "    )\n",
    "\n",
    "    right_fairlets, right_leftovers = tree_fairlet_decomposition(\n",
    "        node.right, X, sensitive\n",
    "    )\n",
    "\n",
    "    combined_indices = left_leftovers + right_leftovers\n",
    "\n",
    "    new_fairlets, final_leftovers = extract_fairlets_from_node(\n",
    "        combined_indices, sensitive\n",
    "    )\n",
    "\n",
    "    total_fairlets = left_fairlets + right_fairlets + new_fairlets\n",
    "\n",
    "    return total_fairlets, final_leftovers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65670f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fairlet_centers(X, fairlets):\n",
    "\n",
    "    centers = []\n",
    "\n",
    "    for fl in fairlets:\n",
    "        pts = X[fl]\n",
    "        D = cdist(pts, pts)\n",
    "        medoid_index = np.argmin(D.sum(axis=1))\n",
    "        centers.append(fl[medoid_index])\n",
    "\n",
    "    return np.array(centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2c32c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmedoids(X, k, max_iter=100):\n",
    "\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "    n = X.shape[0]\n",
    "    medoids = np.random.choice(n, k, replace=False)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "\n",
    "        distances = cdist(X, X[medoids])\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "\n",
    "        new_medoids = []\n",
    "\n",
    "        for i in range(k):\n",
    "            cluster_points = np.where(labels == i)[0]\n",
    "\n",
    "            if len(cluster_points) == 0:\n",
    "                new_medoids.append(medoids[i])\n",
    "                continue\n",
    "\n",
    "            cluster_distances = cdist(\n",
    "                X[cluster_points], X[cluster_points]\n",
    "            )\n",
    "            best = cluster_points[np.argmin(cluster_distances.sum(axis=1))]\n",
    "            new_medoids.append(best)\n",
    "\n",
    "        new_medoids = np.array(new_medoids)\n",
    "\n",
    "        if np.all(new_medoids == medoids):\n",
    "            break\n",
    "\n",
    "        medoids = new_medoids\n",
    "\n",
    "    return labels, medoids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c319e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_labels(fairlets, center_labels, n):\n",
    "\n",
    "    labels = np.zeros(n, dtype=int)\n",
    "\n",
    "    for fl, lab in zip(fairlets, center_labels):\n",
    "        for idx in fl:\n",
    "            labels[idx] = lab\n",
    "\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af91ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairness_metrics(labels, sensitive):\n",
    "\n",
    "    K = len(np.unique(labels))\n",
    "    balances = []\n",
    "    violations = 0\n",
    "\n",
    "    global_ratio = sensitive.mean()\n",
    "    dp_gaps = []\n",
    "\n",
    "    for k in range(K):\n",
    "        mask = labels == k\n",
    "        group = sensitive[mask]\n",
    "\n",
    "        n0 = np.sum(group == 0)\n",
    "        n1 = np.sum(group == 1)\n",
    "\n",
    "        if max(n0, n1) == 0:\n",
    "            continue\n",
    "\n",
    "        balance = min(n0, n1) / max(n0, n1)\n",
    "        balances.append(balance)\n",
    "\n",
    "        if balance < 1.0:   # p:q = 1:1\n",
    "            violations += 1\n",
    "\n",
    "        cluster_ratio = group.mean()\n",
    "        dp_gaps.append(abs(cluster_ratio - global_ratio))\n",
    "\n",
    "    return {\n",
    "        \"avg_balance\": np.mean(balances),\n",
    "        \"violation_rate\": violations / K,\n",
    "        \"avg_dp_gap\": np.mean(dp_gaps)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e1abfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explainability_metrics(X, labels):\n",
    "\n",
    "    clf = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "    clf.fit(X, labels)\n",
    "\n",
    "    return {\n",
    "        \"tree_fidelity\": clf.score(X, labels),\n",
    "        \"tree_depth\": clf.get_depth(),\n",
    "        \"tree_leaves\": clf.get_n_leaves()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1f1bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prototype_quality(X, labels):\n",
    "\n",
    "    K = len(np.unique(labels))\n",
    "    distances = []\n",
    "\n",
    "    for k in range(K):\n",
    "        pts = X[labels == k]\n",
    "        center = pts.mean(axis=0)\n",
    "        d = np.linalg.norm(pts - center, axis=1)\n",
    "        distances.append(np.mean(d))\n",
    "\n",
    "    return np.mean(distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4db6fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    print(\"Loading data...\")\n",
    "    X, sensitive = load_data()\n",
    "\n",
    "    print(\"Building spatial tree...\")\n",
    "    root = build_tree(X, list(range(len(X))))\n",
    "\n",
    "    print(\"Running tree-based fairlet decomposition...\")\n",
    "    fairlets, leftovers = tree_fairlet_decomposition(\n",
    "        root, X, sensitive\n",
    "    )\n",
    "\n",
    "    print(\"\\nFAIRLET SUMMARY\")\n",
    "    print(\"----------------\")\n",
    "    print(\"Total fairlets:\", len(fairlets))\n",
    "    print(\"Total assigned points:\", sum(len(fl) for fl in fairlets))\n",
    "    print(\"Leftovers (unassigned):\", len(leftovers))\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Compute medoids of fairlets\n",
    "    # -------------------------------------------------\n",
    "    centers = compute_fairlet_centers(X, fairlets)\n",
    "\n",
    "    center_labels, medoids = kmedoids(\n",
    "        X[centers],\n",
    "        K_CLUSTERS\n",
    "    )\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Assign fairlet labels to original points\n",
    "    # -------------------------------------------------\n",
    "    labels = np.zeros(len(X), dtype=int)\n",
    "\n",
    "    for fl, lab in zip(fairlets, center_labels):\n",
    "        for idx in fl:\n",
    "            labels[idx] = lab\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Assign leftover points to nearest cluster\n",
    "    # -------------------------------------------------\n",
    "    if len(leftovers) > 0:\n",
    "\n",
    "        # Get actual medoid coordinates\n",
    "        medoid_points = X[centers][medoids]\n",
    "\n",
    "        distances = cdist(X[leftovers], medoid_points)\n",
    "        leftover_labels = np.argmin(distances, axis=1)\n",
    "\n",
    "        for idx, lab in zip(leftovers, leftover_labels):\n",
    "            labels[idx] = lab\n",
    "\n",
    "        print(\"Leftovers assigned to nearest clusters.\")\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # EVALUATION\n",
    "    # -------------------------------------------------\n",
    "\n",
    "    print(\"\\nCLUSTERING QUALITY\")\n",
    "    print(\"------------------\")\n",
    "    print(\"Silhouette:\", silhouette_score(X, labels))\n",
    "    print(\"Davies-Bouldin:\", davies_bouldin_score(X, labels))\n",
    "\n",
    "    print(\"\\nFAIRNESS\")\n",
    "    print(\"--------\")\n",
    "    fm = fairness_metrics(labels, sensitive)\n",
    "    for k, v in fm.items():\n",
    "        print(k, \":\", v)\n",
    "\n",
    "    print(\"\\nEXPLAINABILITY\")\n",
    "    print(\"--------------\")\n",
    "    em = explainability_metrics(X, labels)\n",
    "    for k, v in em.items():\n",
    "        print(k, \":\", v)\n",
    "\n",
    "    print(\"\\nPROTOTYPE QUALITY\")\n",
    "    print(\"-----------------\")\n",
    "    print(\"avg_distance:\", prototype_quality(X, labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee50917f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Building spatial tree...\n",
      "Running tree-based fairlet decomposition...\n",
      "\n",
      "FAIRLET SUMMARY\n",
      "----------------\n",
      "Total fairlets: 327\n",
      "Total assigned points: 654\n",
      "Leftovers (unassigned): 346\n",
      "Leftovers assigned to nearest clusters.\n",
      "\n",
      "CLUSTERING QUALITY\n",
      "------------------\n",
      "Silhouette: 0.028280387525811638\n",
      "Davies-Bouldin: 4.354095400585686\n",
      "\n",
      "FAIRNESS\n",
      "--------\n",
      "avg_balance : 0.5052515300791164\n",
      "violation_rate : 1.0\n",
      "avg_dp_gap : 0.02373685542593103\n",
      "\n",
      "EXPLAINABILITY\n",
      "--------------\n",
      "tree_fidelity : 0.753\n",
      "tree_depth : 4\n",
      "tree_leaves : 16\n",
      "\n",
      "PROTOTYPE QUALITY\n",
      "-----------------\n",
      "avg_distance: 3.0956377337096885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91773\\AppData\\Local\\Temp\\ipykernel_20716\\29975366.py:21: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  categorical_cols = X_raw.select_dtypes(include=['object']).columns\n"
     ]
    }
   ],
   "source": [
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b598266e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvirtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
